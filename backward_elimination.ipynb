{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2829e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    'StudyHours': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'PrevExamScore': [30, 40, 45, 50, 60, 65, 70, 75, 80, 85],\n",
    "    'Pass': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]  # 0 = Fail, 1 = Pass\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Features and target variable\n",
    "X = df[['StudyHours', 'PrevExamScore']]\n",
    "y = df['Pass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cafc55e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Add a constant (for the intercept)\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91c2c2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   Pass   R-squared:                       0.758\n",
      "Model:                            OLS   Adj. R-squared:                  0.688\n",
      "Method:                 Least Squares   F-statistic:                     10.94\n",
      "Date:                Sun, 12 Oct 2025   Prob (F-statistic):            0.00701\n",
      "Time:                        09:41:09   Log-Likelihood:               -0.17258\n",
      "No. Observations:                  10   AIC:                             6.345\n",
      "Df Residuals:                       7   BIC:                             7.253\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const            -0.3333      1.464     -0.228      0.826      -3.796       3.129\n",
      "StudyHours        0.1515      0.324      0.468      0.654      -0.615       0.918\n",
      "PrevExamScore  6.939e-18      0.054   1.29e-16      1.000      -0.127       0.127\n",
      "==============================================================================\n",
      "Omnibus:                        0.086   Durbin-Watson:                   1.491\n",
      "Prob(Omnibus):                  0.958   Jarque-Bera (JB):                0.311\n",
      "Skew:                          -0.000   Prob(JB):                        0.856\n",
      "Kurtosis:                       2.136   Cond. No.                     1.01e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.01e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using OLS regression\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Display the model summary (including p-values)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c274a269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: PrevExamScore with p-value: 0.9999999999999999\n",
      "Removing feature: const with p-value: 0.11419580126842226\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                   Pass   R-squared (uncentered):                   0.831\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.812\n",
      "Method:                 Least Squares   F-statistic:                              44.31\n",
      "Date:                Sun, 12 Oct 2025   Prob (F-statistic):                    9.31e-05\n",
      "Time:                        09:41:09   Log-Likelihood:                         -1.8294\n",
      "No. Observations:                  10   AIC:                                      5.659\n",
      "Df Residuals:                       9   BIC:                                      5.961\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "StudyHours     0.1039      0.016      6.656      0.000       0.069       0.139\n",
      "==============================================================================\n",
      "Omnibus:                        0.710   Durbin-Watson:                   1.054\n",
      "Prob(Omnibus):                  0.701   Jarque-Bera (JB):                0.557\n",
      "Skew:                          -0.000   Prob(JB):                        0.757\n",
      "Kurtosis:                       1.844   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Set a significance level\n",
    "significance_level = 0.05\n",
    "\n",
    "# Perform backward elimination\n",
    "while True:\n",
    "    # Fit the model\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # Get the highest p-value in the model\n",
    "    max_p_value = model.pvalues.max()\n",
    "    \n",
    "    # Check if the highest p-value is greater than the significance level\n",
    "    if max_p_value > significance_level:\n",
    "        # Identify the feature with the highest p-value\n",
    "        feature_to_remove = model.pvalues.idxmax()\n",
    "        print(f\"Removing feature: {feature_to_remove} with p-value: {max_p_value}\")\n",
    "        \n",
    "        # Drop the feature\n",
    "        X = X.drop(columns=[feature_to_remove])\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Display the final model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cd7d81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: PrevExamScore (p-value = 1.0000)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   Pass   R-squared:                       0.758\n",
      "Model:                            OLS   Adj. R-squared:                  0.727\n",
      "Method:                 Least Squares   F-statistic:                     25.00\n",
      "Date:                Sun, 12 Oct 2025   Prob (F-statistic):            0.00105\n",
      "Time:                        09:41:09   Log-Likelihood:               -0.17258\n",
      "No. Observations:                  10   AIC:                             4.345\n",
      "Df Residuals:                       8   BIC:                             4.950\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.5000      0.087      5.745      0.000       0.299       0.701\n",
      "StudyHours     0.4352      0.087      5.000      0.001       0.234       0.636\n",
      "==============================================================================\n",
      "Omnibus:                        0.086   Durbin-Watson:                   1.491\n",
      "Prob(Omnibus):                  0.958   Jarque-Bera (JB):                0.311\n",
      "Skew:                          -0.000   Prob(JB):                        0.856\n",
      "Kurtosis:                       2.136   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1) Sample data\n",
    "# -------------------------------------------------------------------\n",
    "data = {\n",
    "    \"StudyHours\":     [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    \"PrevExamScore\":  [30, 40, 45, 50, 60, 65, 70, 75, 80, 85],\n",
    "    \"Pass\":           [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]  # 0 = Fail, 1 = Pass (note: OLS on 0/1 is for demo; Logit is more appropriate)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2) Features/target + STANDARDIZATION\n",
    "#    Why standardize here?\n",
    "#    - Makes coefficients comparable (per 1 SD increase).\n",
    "#    - Improves numerical conditioning; p-values/selection become more stable.\n",
    "#    - For OLS specifically, scale does not change fit quality, but it helps interpretation.\n",
    "# -------------------------------------------------------------------\n",
    "X_raw = df[[\"StudyHours\", \"PrevExamScore\"]]\n",
    "y = df[\"Pass\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_raw)                          # mean=0, std=1 for each feature\n",
    "X = pd.DataFrame(X_scaled, columns=X_raw.columns, index=df.index)\n",
    "\n",
    "# Add intercept AFTER scaling (do NOT scale the constant)\n",
    "X = sm.add_constant(X, has_constant=\"add\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3) Initial OLS fit (on standardized features)\n",
    "# -------------------------------------------------------------------\n",
    "model = sm.OLS(y, X).fit()\n",
    "# print(model.summary())\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4) Backward elimination by p-values (keep the intercept!)\n",
    "#    - At each step, drop the non-constant feature with the largest p-value\n",
    "#      if it exceeds the significance threshold.\n",
    "# -------------------------------------------------------------------\n",
    "alpha = 0.05  # significance level\n",
    "\n",
    "while True:\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    # Consider only feature p-values (exclude intercept/const from elimination)\n",
    "    pvals = model.pvalues.drop(\"const\", errors=\"ignore\")\n",
    "\n",
    "    # If there are no removable features, or all are significant, stop\n",
    "    if pvals.empty:\n",
    "        break\n",
    "\n",
    "    worst_feat = pvals.idxmax()\n",
    "    worst_p = pvals.max()\n",
    "\n",
    "    if worst_p > alpha:\n",
    "        print(f\"Removing feature: {worst_feat} (p-value = {worst_p:.4f})\")\n",
    "        X = X.drop(columns=[worst_feat])\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5) Final model summary\n",
    "# -------------------------------------------------------------------\n",
    "print(model.summary())\n",
    "\n",
    "# --------------------------\n",
    "# Notes:\n",
    "# - Coefficients now reflect the change in y per 1 standard deviation\n",
    "#   increase in each feature (since X was standardized).\n",
    "# - The intercept corresponds to the prediction when features are at\n",
    "#   their means (which is 0 after standardization).\n",
    "# - For a binary target like 'Pass', consider statsmodels.Logit for\n",
    "#   a proper classification model.\n",
    "# --------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea6bcaf",
   "metadata": {},
   "source": [
    "## Comparison: OLS with backward elimination â unstandardized vs standardized\n",
    "\n",
    "### What your two outputs show (essentials)\n",
    "- **Unstandardized**\n",
    "  - Dropped: `PrevExamScore` (p â 1.0) **and `const`** (p â 0.114).\n",
    "  - Remaining term: `StudyHours` with `coef â 0.1039` (per **1 hour**).\n",
    "  - Reported **RÂ² (uncentered) = 0.831** (no intercept in the model).\n",
    "\n",
    "- **Standardized**\n",
    "  - Dropped: `PrevExamScore` (p = 1.0).\n",
    "  - Kept: `const` (p â 0.000) and `StudyHours`.\n",
    "  - `const â 0.5`, `StudyHours coef â 0.4352` (per **1 SD** of StudyHours).\n",
    "  - Reported **RÂ² = 0.758** (with intercept; regular centered RÂ²).\n",
    "\n",
    "---\n",
    "\n",
    "### Why the results differ\n",
    "\n",
    "1) **Intercept handling (const)**\n",
    "   - Without scaling, backward elimination removed `const` â OLS reports **uncentered RÂ²**, which tends to be **inflated** and is **not comparable** to centered RÂ².\n",
    "   - With scaling, features are mean-centered (0), so the intercept equals the **mean of y** (~0.5 for a 0/1 target) and is significant â `const` is retained.\n",
    "\n",
    "2) **Coefficient meaning (scale vs SD)**\n",
    "   - Unstandardized `0.1039` = change in y per **1 hour** of study.\n",
    "   - Standardized `0.4352` = change in y per **1 standard deviation** increase in StudyHours.\n",
    "   - These magnitudes are **not directly comparable** because the units differ.\n",
    "\n",
    "3) **Strong collinearity drives variable removal**\n",
    "   - `StudyHours` and `PrevExamScore` are highly correlated (â **0.994**).  \n",
    "     Under OLS + backward elimination, such collinearity often leads to keeping **one** predictor and assigning a huge p-value (~1.0) to the other.\n",
    "\n",
    "4) **RÂ² comparability**\n",
    "   - Do **not** compare uncentered RÂ² (no intercept) with centered RÂ² (with intercept).  \n",
    "     Prefer centered RÂ² for model comparison.\n",
    "\n",
    "---\n",
    "\n",
    "### How to interpret / which to use\n",
    "\n",
    "- If you want **natural-unit effects** (âper 1 hourâ), use **unstandardi**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coursera-microsoft-ml-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
